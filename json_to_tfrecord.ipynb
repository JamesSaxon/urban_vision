{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "from object_detection.utils import dataset_util\n",
    "import os, glob\n",
    "from PIL import Image\n",
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/amandawhaley/Projects/UrbanVision/images_to_test/output_test.json')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_IMAGE_DATA_DIR = pathlib.Path('/Users/amandawhaley/Projects/UrbanVision/images_to_test')\n",
    "TRAIN_IMAGE_DATA_PATHS = list(TRAIN_IMAGE_DATA_DIR.glob(\"*.json\"))\n",
    "TRAIN_IMAGE_DATA_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example data set for one file.\n",
    "sample_example = {}\n",
    "sample_example['file_name']='/Users/amandawhaley/Projects/UrbanVision/53_hp_morning/frame_010.jpg'\n",
    "sample_example['image_width']=1500\n",
    "sample_example['image_height']=1000\n",
    "sample_example['xmins']=[750, 1000, 100]\n",
    "sample_example['xmaxs']=[800, 1250, 800]\n",
    "sample_example['ymins']=[150, 300, 750]\n",
    "sample_example['ymaxs']=[350, 420, 1000]\n",
    "sample_example['classes']=[1, 3, 2]\n",
    "sample_example['classes_text']=[b'person', b'car', b'bus']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_example(example):   \n",
    "    with tf.io.gfile.GFile(example['file_name'], 'rb') as fid:\n",
    "        encoded_image_data = fid.read()\n",
    "    \n",
    "    image_filename = str.encode(example['file_name'])\n",
    "    height = example['image_height']\n",
    "    width = example['image_width']\n",
    "    image_format = b'jpg'\n",
    "\n",
    "    xmins = list(np.array(example['xmins'])/width) # List of normalized left x coordinates in bounding box (1 per box)\n",
    "    xmaxs = list(np.array(example['xmaxs'])/width) # List of normalized right x coordinates in bounding box\n",
    "             # (1 per box)\n",
    "    ymins = list(np.array(example['ymins'])/height) # List of normalized top y coordinates in bounding box (1 per box)\n",
    "    ymaxs = list(np.array(example['ymaxs'])/height) # List of normalized bottom y coordinates in bounding box\n",
    "             # (1 per box)\n",
    "    classes_text = []\n",
    "    for label in example['classes_text']:\n",
    "        classes_text.append(label.encode('utf-8')) # List of string class name of bounding box (1 per box)\n",
    "    classes = example['classes'] # List of integer class id of bounding box (1 per box)\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(image_filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(image_filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_example = create_tf_example(sample_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = tf.compat.v1.flags\n",
    "flags.DEFINE_string('output_path', '', \"/Users/amandawhaley/Projects/UrbanVision/models/research/train.record\")\n",
    "flags.DEFINE_string('f', '', 'kernel') #Had to add this workaround - not sure why\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS.output_path = \"/Users/amandawhaley/Projects/UrbanVision/models/research/train.record\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_name': '/Users/amandawhaley/Projects/UrbanVision/53_hp_morning/frame_010.jpg', 'image_width': 1500, 'image_height': 1200, 'xmins': [750, 1000, 100], 'xmaxs': [800, 1250, 800], 'ymins': [150, 300, 750], 'ymaxs': [350, 420, 1000], 'classes': [1, 3, 2], 'classes_text': ['person', 'car', 'bus']}\n"
     ]
    }
   ],
   "source": [
    "writer = tf.io.TFRecordWriter(FLAGS.output_path)\n",
    "for data_json in TRAIN_IMAGE_DATA_PATHS:\n",
    "    with open(data_json, mode='r') as json_file: \n",
    "        example = json.load(json_file)\n",
    "    print(example)\n",
    "    tf_example = create_tf_example(example)\n",
    "    writer.write(tf_example.SerializeToString())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (UrbanVision)",
   "language": "python",
   "name": "urbanvision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
